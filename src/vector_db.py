# @title src/vector_db.py
import os
import shutil
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain_core.documents import Document
from typing import List


class RFPVectorDB:
    def __init__(self, db_path: str = "./chroma_db"):
        """
        :param db_path: ë²¡í„° DBê°€ ì €ì¥ë  ë¡œì»¬ ê²½ë¡œ
        """
        self.db_path = db_path
        self.embedding_model = OpenAIEmbeddings(model="text-embedding-3-small")  # ê°€ì„±ë¹„ ì¢‹ì€ ëª¨ë¸
        self.vector_store = None

    def create_vector_db(self, documents: List[Document], force_rebuild: bool = False):
        """
        ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ ì²­í‚¹ í›„ ë²¡í„° DBë¥¼ ìƒì„± ë° ì €ì¥í•©ë‹ˆë‹¤.
        :param force_rebuild: Trueì¼ ê²½ìš° ê¸°ì¡´ DBë¥¼ ì‚­ì œí•˜ê³  ìƒˆë¡œ ë§Œë“­ë‹ˆë‹¤.
        """
        # ê¸°ì¡´ DBê°€ ìˆê³  ê°•ì œ ì¬ìƒì„±ì´ ì•„ë‹ˆë©´ ë¡œë“œë§Œ ì‹œë„
        if os.path.exists(self.db_path) and not force_rebuild:
            print(f"ğŸ“‚ ê¸°ì¡´ ë²¡í„° DBë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤. (ê²½ë¡œ: {self.db_path})")
            self.vector_store = Chroma(
                persist_directory=self.db_path,
                embedding_function=self.embedding_model
            )
            return

        # DB ì¬ìƒì„± ë¡œì§
        if force_rebuild and os.path.exists(self.db_path):
            print("ğŸ—‘ï¸ ê¸°ì¡´ DBë¥¼ ì‚­ì œí•˜ê³  ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤...")
            shutil.rmtree(self.db_path)  # í´ë” ì‚­ì œ

        print("âœ‚ï¸ ë¬¸ì„œë¥¼ ì²­í‚¹(Chunking) ì¤‘ì…ë‹ˆë‹¤...")
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,  # í•œ ì¡°ê°ì˜ ìµœëŒ€ ê¸¸ì´
            chunk_overlap=200  # ì¡°ê° ê°„ ì¤‘ë³µë˜ëŠ” ê¸¸ì´ (ë¬¸ë§¥ ëŠê¹€ ë°©ì§€)
        )
        split_docs = text_splitter.split_documents(documents)
        print(f"ğŸ§© ì²­í‚¹ ì™„ë£Œ! ì´ {len(split_docs)}ê°œì˜ ì²­í¬ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")

        print("ğŸ’¾ ë²¡í„° DBì— ì €ì¥ ì¤‘ì…ë‹ˆë‹¤... (ì‹œê°„ì´ ì¡°ê¸ˆ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
        self.vector_store = Chroma.from_documents(
            documents=split_docs,
            embedding=self.embedding_model,
            persist_directory=self.db_path
        )
        print("âœ… ë²¡í„° DB ì €ì¥ ì™„ë£Œ!")

    def get_retriever(self):
        """
        ê²€ìƒ‰ê¸°(Retriever) ê°ì²´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        if self.vector_store is None:
            # DBê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ë‹¤ë©´ ë¡œë“œ ì‹œë„
            self.vector_store = Chroma(
                persist_directory=self.db_path,
                embedding_function=self.embedding_model
            )

        # ê²€ìƒ‰ ì˜µì…˜ ì„¤ì • (k=3: ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œ 3ê°œ ë°˜í™˜)
        return self.vector_store.as_retriever(search_kwargs={"k": 3})