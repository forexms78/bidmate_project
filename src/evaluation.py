# @title src/evaluation.py
import pandas as pd
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from dotenv import load_dotenv

load_dotenv()


class RFPEvaluator:
    def __init__(self, generator):
        self.generator = generator
        # ì±„ì ì€ ê°€ì¥ ë˜‘ë˜‘í•˜ê³  ì €ë ´í•œ ëª¨ë¸ë¡œ ìˆ˜í–‰
        self.judge_llm = ChatOpenAI(model="gpt-5", temperature=0)

    def _judge_answer(self, question, ground_truth, ai_answer):
        judge_template = """
        ë‹¹ì‹ ì€ ì…ì°° ë¬¸ì„œ ë¶„ì„ ì‹œìŠ¤í…œì˜ ìœ ì—°í•œ ì±„ì ê´€ì…ë‹ˆë‹¤.
        [ì§ˆë¬¸]ì— ëŒ€í•œ [AI ë‹µë³€]ì´ [ì‹¤ì œ ì •ë‹µ]ê³¼ ë§¥ë½ìƒ ì¼ì¹˜í•˜ê±°ë‚˜, ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ ë” ì˜ íŒŒì•…í–ˆë‹¤ë©´ "ì •ë‹µ" ì²˜ë¦¬í•˜ì„¸ìš”.

        [ì±„ì  ê°€ì´ë“œ - í•„ë…]
        1. **ìˆ«ì/ê¸ˆì•¡**: 1ì–µ 3ì²œë§Œ ì› = 130,000,000 = 1.3ì–µ (ëª¨ë‘ ì •ë‹µ). ë¶€ê°€ì„¸ í¬í•¨/ë³„ë„ ì–¸ê¸‰ì€ í—ˆìš©.
        2. **ê¸°ê´€ëª…**: 'í•œì˜ëŒ€í•™' = 'í•œì˜ëŒ€í•™êµ' (ë™ì¼ ê¸°ê´€ì´ë©´ ì •ë‹µ).
        3. **ğŸš¨ ë¬¸ì„œ ìœ í˜• vs í™•ì¥ì (ê°€ì¥ ì¤‘ìš”)**:
           - ì§ˆë¬¸ì´ "ë¬¸ì„œ ìœ í˜•"ì„ ë¬»ëŠ”ë° ì •ë‹µì´ 'hwp', 'pdf' ë“± **í™•ì¥ì**ì¸ ê²½ìš°:
             AIê°€ 'ì œì•ˆìš”ì²­ì„œ', 'RFP', 'ê³µê³ ë¬¸' ë“± **ë¬¸ì„œì˜ ì„±ê²©**ì„ ë§ê²Œ ëŒ€ë‹µí–ˆë‹¤ë©´ **ë¬´ì¡°ê±´ "ì •ë‹µ"**ìœ¼ë¡œ íŒì •í•˜ì„¸ìš”.
           - ë°˜ëŒ€ë¡œ AIê°€ í™•ì¥ì(hwp)ë¥¼ ë§ì¶°ë„ ì •ë‹µì…ë‹ˆë‹¤. (ë‘˜ ë‹¤ í—ˆìš©)
        4. **ì •ë³´ ë¶€ì¬**: ì •ë‹µì´ ìˆëŠ”ë° AIê°€ "ëª¨ë¥´ê² ë‹¤"ê³  í•˜ë©´ "ì˜¤ë‹µ".

        [ë°ì´í„°]
        - ì§ˆë¬¸: {question}
        - ì‹¤ì œ ì •ë‹µ(Ground Truth): {ground_truth}
        - AI ë‹µë³€: {ai_answer}

        íŒì • ê²°ê³¼ëŠ” ì˜¤ì§ "ì •ë‹µ" ë˜ëŠ” "ì˜¤ë‹µ"ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”.
        íŒì •:
        """
        prompt = ChatPromptTemplate.from_template(judge_template)
        chain = prompt | self.judge_llm | StrOutputParser()

        return chain.invoke({
            "question": question,
            "ground_truth": str(ground_truth),
            "ai_answer": ai_answer
        })

    def evaluate(self, dataset: pd.DataFrame, progress_callback=None):
        results = []
        correct_count = 0
        total = len(dataset)

        for i, row in dataset.iterrows():
            # ì»¬ëŸ¼ëª… í˜¸í™˜ì„± ì²˜ë¦¬ (í•œê¸€/ì˜ì–´)
            question = row.get('ì§ˆë¬¸') or row.get('question')
            ground_truth = row.get('ì •ë‹µ') or row.get('ground_truth')

            if not question: continue

            # AI ë‹µë³€ ìƒì„±
            ai_answer = self.generator.generate_answer(question)

            # ìœ ì—°í•œ ì±„ì 
            result_text = self._judge_answer(question, ground_truth, ai_answer)
            is_correct = "ì •ë‹µ" in result_text

            if is_correct:
                correct_count += 1

            results.append({
                "ì§ˆë¬¸": question,
                "ì •ë‹µ": ground_truth,
                "AI ë‹µë³€": ai_answer,
                "ê²°ê³¼": "ì •ë‹µ" if is_correct else "ì˜¤ë‹µ"
            })

            # ì§„í–‰ë¥  ì½œë°±
            if progress_callback:
                progress_callback((i + 1) / total, f"ì±„ì  ì¤‘: {i + 1}/{total}")

        accuracy = (correct_count / total) * 100
        return accuracy, results