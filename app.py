# @title app.py (ìµœì¢… ìˆ˜ì •ë³¸)
import os
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import time
from langchain_core.messages import HumanMessage, AIMessage

# ëª¨ë“ˆ ì„í¬íŠ¸
from src.data_loader import RFPDataLoader
from src.vector_db import RFPVectorDB
from src.generator import RFPGenerator
from local_src.local_generator import LocalRFPGenerator
from src.evaluation import RFPEvaluator
from src.evaluation_dataset_builder import build_eval_dataset

# ê·¸ë˜í”„ í•œê¸€ ì„¤ì •
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False

st.set_page_config(page_title="ì…ì°°ë©”ì´íŠ¸ í†µí•© RAG", page_icon="ğŸ¢", layout="wide")

# ==========================================
# [ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”]
# ==========================================
if "initialized_b" not in st.session_state:
    st.session_state.update({
        "initialized_b": False, "history_b": [], "gen_b": None,
        "initialized_a": False, "history_a": [], "gen_a": None,
        "comparison_results": None, "acc_b": 0, "acc_a": 0, "docs": None,
        "load_error_b": None, "load_error_a": None
    })


# ==========================================
# [ìë™ ì—”ì§„ ë¡œë“œ]
# ==========================================
def auto_initialize():
    base_dir = os.path.dirname(os.path.abspath(__file__))
    csv_path = os.path.join(base_dir, "DATA", "data_list.csv")
    db_path_b = os.path.join(base_dir, "chroma_db")
    db_path_a = os.path.join(base_dir, "local_chroma_db")

    if not os.path.exists(csv_path): return

    # 1. GPT ì—”ì§„ ìë™ ë¡œë“œ
    if not st.session_state.initialized_b and os.path.exists(db_path_b):
        try:
            with st.spinner("GPT ì—”ì§„ ì—°ê²° ì¤‘..."):
                loader = RFPDataLoader(file_path=csv_path)
                docs = loader.load(use_summary=False)
                db = RFPVectorDB(db_path=db_path_b)
                store = db.create_vector_db(docs, force_rebuild=False)
                gen_b = RFPGenerator(store)
                gen_b.init_retriever(docs)
                st.session_state.initialized_b = True
                st.session_state.gen_b = gen_b
                st.session_state.docs = docs
                st.session_state.load_error_b = None
        except Exception as e:
            st.session_state.load_error_b = str(e)

    # 2. ë¡œì»¬ ì—”ì§„ ìë™ ë¡œë“œ
    if not st.session_state.initialized_a and os.path.exists(db_path_a):
        try:
            loader = RFPDataLoader(file_path=csv_path)
            docs = loader.load(use_summary=False)
            db = RFPVectorDB(db_path=db_path_a)
            store = db.create_vector_db(docs, force_rebuild=False)
            gen_a = LocalRFPGenerator(store)
            gen_a.init_retriever(docs)
            st.session_state.initialized_a = True
            st.session_state.gen_a = gen_a
            st.session_state.docs = docs
            st.session_state.load_error_a = None
        except Exception as e:
            st.session_state.load_error_a = str(e)


auto_initialize()

st.title("ğŸ¢ ì…ì°°ë©”ì´íŠ¸ í†µí•© RAG ëŒ€ì‹œë³´ë“œ")

# ==========================================
# [ì‚¬ì´ë“œë°” UI]
# ==========================================
with st.sidebar:
    st.header("âš™ï¸ ì—”ì§„ ìƒíƒœ")

    # GPT ìƒíƒœ
    if st.session_state.initialized_b:
        st.success("API: ğŸŸ¢ ê°€ë™ë¨")
    else:
        st.error("API: ğŸ”´ ì¤‘ë‹¨ë¨")
        if st.session_state.load_error_b:
            st.caption(f"âš ï¸ {st.session_state.load_error_b}")
        if os.path.exists(os.path.join(os.path.dirname(os.path.abspath(__file__)), "chroma_db")):
            if st.button("ğŸ”Œ API ê¸´ê¸‰ ì—°ê²°"):
                auto_initialize()
                st.rerun()

    # ë¡œì»¬ ìƒíƒœ
    if st.session_state.initialized_a:
        st.success("ë¡œì»¬: ğŸŸ¢ ê°€ë™ë¨")
    else:
        st.error("ë¡œì»¬: ğŸ”´ ì¤‘ë‹¨ë¨")
        if st.session_state.load_error_a:
            st.caption(f"âš ï¸ {st.session_state.load_error_a}")
        if os.path.exists(os.path.join(os.path.dirname(os.path.abspath(__file__)), "local_chroma_db")):
            if st.button("ğŸ”Œ ë¡œì»¬ ê¸´ê¸‰ ì—°ê²°"):
                auto_initialize()
                st.rerun()

    st.divider()
    st.header("ğŸ› ï¸ Vector DB êµ¬ì¶•")
    use_summary = st.checkbox("ë¬¸ì„œ ìš”ì•½ì„ í†µí•œ êµ¬ì¶•", value=True)

    col_b, col_a = st.columns(2)
    with col_b:
        if st.button("API êµ¬ì¶•"):
            with st.spinner("GPT DB ì¬êµ¬ì¶• ì¤‘..."):
                loader = RFPDataLoader(file_path=os.path.join("DATA", "data_list.csv"))
                docs = loader.load(use_summary=use_summary)
                db = RFPVectorDB(db_path="./chroma_db")
                store = db.create_vector_db(docs, force_rebuild=True)
                gen_b = RFPGenerator(store)
                gen_b.init_retriever(docs)
                st.session_state.update({"gen_b": gen_b, "initialized_b": True})
            st.success("ì™„ë£Œ")
            st.rerun()

    with col_a:
        if st.button("ë¡œì»¬ êµ¬ì¶•"):
            with st.spinner("ë¡œì»¬ DB ì¬êµ¬ì¶• ì¤‘..."):
                loader = RFPDataLoader(file_path=os.path.join("DATA", "data_list.csv"))
                docs = loader.load(use_summary=False)
                db = RFPVectorDB(db_path="./local_chroma_db")
                store = db.create_vector_db(docs, force_rebuild=True)
                gen_a = LocalRFPGenerator(store)
                gen_a.init_retriever(docs)
                st.session_state.update({"gen_a": gen_a, "initialized_a": True})
            st.success("ì™„ë£Œ")
            st.rerun()

    st.divider()
    st.header("ğŸ“Š A vs B ì„±ëŠ¥ ë¹„êµ í‰ê°€")
    eval_count = st.number_input("í‰ê°€ ë¬¸í•­ ìˆ˜ (MAX 100)", min_value=1, max_value=100, value=5)

    # --- [ìˆ˜ì • ì™„ë£Œ] ë²„íŠ¼ ë° í‰ê°€ ë¡œì§ ---
    if st.button("ğŸ ì„±ëŠ¥ ë¹„êµ ì‹œì‘"):
        if st.session_state.initialized_a and st.session_state.initialized_b:
            progress_bar = st.progress(0)
            status_text = st.empty()


            def update_progress(percent, msg):
                progress_bar.progress(percent)
                status_text.write(msg)


            try:
                # 1. ë°ì´í„° ìƒì„±
                status_text.write("ğŸ“š í‰ê°€ ë°ì´í„° ìƒì„± ì¤‘...")
                raw_data = build_eval_dataset(os.path.join("DATA", "data_list.csv"), sample_size=eval_count)
                test_ds = pd.DataFrame(raw_data)

                # 2. GPT-5 í‰ê°€
                status_text.write("ğŸ¤– GPT-5 ì±„ì  ì‹œì‘...")
                eval_b = RFPEvaluator(st.session_state.gen_b)
                try:
                    acc_b, res_b = eval_b.evaluate(test_ds, progress_callback=lambda p, m: update_progress(p,
                                                                                                           f"GPT-5 í‰ê°€ ì¤‘: {int(p * 100)}%"))
                except TypeError:
                    acc_b, res_b = eval_b.evaluate(test_ds)

                # 3. ë¡œì»¬ í‰ê°€
                status_text.write("ğŸ  ë¡œì»¬ ëª¨ë¸ ì±„ì  ì‹œì‘...")
                eval_a = RFPEvaluator(st.session_state.gen_a)
                try:
                    acc_a, res_a = eval_a.evaluate(test_ds, progress_callback=lambda p, m: update_progress(p,
                                                                                                           f"ë¡œì»¬ ëª¨ë¸ í‰ê°€ ì¤‘: {int(p * 100)}%"))
                except TypeError:
                    acc_a, res_a = eval_a.evaluate(test_ds)

                # 4. ê²°ê³¼ í†µí•© (ë“¤ì—¬ì“°ê¸° ìˆ˜ì •ë¨: try-except ë°–ìœ¼ë¡œ ì´ë™í•˜ì—¬ ë¬´ì¡°ê±´ ì‹¤í–‰)
                status_text.write("ğŸ“Š ê²°ê³¼ ì§‘ê³„ ì¤‘...")
                comp = []
                for i, (b_res, a_res) in enumerate(zip(res_b, res_a)):
                    origin_file = test_ds.iloc[i].get('source', 'íŒŒì¼ì •ë³´ì—†ìŒ')
                    comp.append({
                        "íŒŒì¼ëª…": origin_file,
                        "ì§ˆë¬¸": b_res.get('ì§ˆë¬¸') or b_res.get('question'),
                        "ì •ë‹µ": b_res.get('ì •ë‹µ') or b_res.get('ground_truth'),
                        "GPT": b_res['AI ë‹µë³€'],
                        "GPTê²°ê³¼": "âœ…" if b_res['ê²°ê³¼'] == "ì •ë‹µ" else "âŒ",
                        "ë¡œì»¬": a_res['AI ë‹µë³€'],
                        "ë¡œì»¬ê²°ê³¼": "âœ…" if a_res['ê²°ê³¼'] == "ì •ë‹µ" else "âŒ"
                    })

                st.session_state.update({
                    "comparison_results": comp,
                    "acc_b": acc_b,
                    "acc_a": acc_a
                })

                status_text.success("âœ… í‰ê°€ ì™„ë£Œ! ë¦¬í¬íŠ¸ íƒ­ì„ í™•ì¸í•˜ì„¸ìš”.")
                progress_bar.progress(100)
                time.sleep(1)
                st.balloons()
                st.rerun()  # ê²°ê³¼ ë°˜ì˜ì„ ìœ„í•´ í™”ë©´ ìƒˆë¡œê³ ì¹¨

            except Exception as e:
                st.error(f"í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        else:
            st.error("âš ï¸ ë‘ ì—”ì§„ì„ ë¨¼ì € ê°€ë™í•´ì£¼ì„¸ìš”!")

# ==========================================
# [ë©”ì¸ í™”ë©´ íƒ­ êµ¬ì„±]
# ==========================================
t1, t2, t3 = st.tabs(["ğŸ’¬ GPT-5 ì±„íŒ…", "ğŸ  ë¡œì»¬ ì±„íŒ…", "ğŸ“Š ì„±ëŠ¥ ë¹„êµ"])

with t1:
    if st.session_state.initialized_b:
        st.success("âœ… GPT-5 ì¤€ë¹„ ì™„ë£Œ")
        for m in st.session_state.history_b:
            with st.chat_message("user" if isinstance(m, HumanMessage) else "assistant"):
                st.write(m.content)
        if p := st.chat_input("GPTì—ê²Œ ì§ˆë¬¸", key="chat_b"):
            st.session_state.history_b.append(HumanMessage(content=p))
            st.chat_message("user").write(p)
            ans = st.session_state.gen_b.generate_answer(p)
            st.session_state.history_b.append(AIMessage(content=ans))
            st.chat_message("assistant").write(ans)
    else:
        st.warning("GPT ì—”ì§„ ë¯¸ì‘ë™: ì‚¬ì´ë“œë°”ì—ì„œ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”.")

with t2:
    if st.session_state.initialized_a:
        st.success("âœ… ë¡œì»¬ Llama3 ì¤€ë¹„ ì™„ë£Œ")
        for m in st.session_state.history_a:
            with st.chat_message("user" if isinstance(m, HumanMessage) else "assistant"):
                st.write(m.content)
        if p := st.chat_input("ë¡œì»¬ ëª¨ë¸ì—ê²Œ ì§ˆë¬¸", key="chat_a"):
            st.session_state.history_a.append(HumanMessage(content=p))
            st.chat_message("user").write(p)
            ans = st.session_state.gen_a.generate_answer(p)
            st.session_state.history_a.append(AIMessage(content=ans))
            st.chat_message("assistant").write(ans)
    else:
        st.warning("ë¡œì»¬ ì—”ì§„ ë¯¸ì‘ë™: ì‚¬ì´ë“œë°”ì—ì„œ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”.")

with t3:
    if st.session_state.comparison_results:
        st.subheader("ğŸ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ë¦¬í¬íŠ¸")
        c1, c2 = st.columns([1, 2])  # ë¹„ìœ¨ ì¡°ì • (ê·¸ë˜í”„:í‘œ)

        with c1:
            # ë§‰ëŒ€ ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
            fig, ax = plt.subplots(figsize=(4, 4))
            bars = ax.bar(['GPT', 'Local'], [st.session_state.acc_b, st.session_state.acc_a],
                          color=['#81B29A', '#E07A5F'])
            ax.set_ylim(0, 100)
            ax.set_ylabel("ì •í™•ë„ (%)")
            ax.set_title("ëª¨ë¸ ì •í™•ë„ ë¹„êµ")

            # ë§‰ëŒ€ ìœ„ì— ì ìˆ˜ í‘œì‹œ
            for bar in bars:
                height = bar.get_height()
                ax.text(bar.get_x() + bar.get_width() / 2.0, height, f'{height:.1f}%', ha='center', va='bottom')

            st.pyplot(fig, use_container_width=True)

            st.metric("GPT ì •í™•ë„", f"{st.session_state.acc_b}%")
            st.metric("ë¡œì»¬ ì •í™•ë„", f"{st.session_state.acc_a}%")

        with c2:
            st.write("### ğŸ“‹ ìƒì„¸ ê²°ê³¼í‘œ")
            st.dataframe(pd.DataFrame(st.session_state.comparison_results), use_container_width=True, height=500)
    else:
        st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ 'ì„±ëŠ¥ ë¹„êµ ì‹œì‘' ë²„íŠ¼ì„ ëˆŒëŸ¬ í‰ê°€ë¥¼ ì§„í–‰í•˜ì„¸ìš”.")